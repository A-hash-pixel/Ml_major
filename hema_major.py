# -*- coding: utf-8 -*-
"""hema_major.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1juYWxmEy_5LA1ZU5fgp27rX-7FNLuZYM

**Installing the required Libraries**
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install dtale

"""**Importing the Required Libraries**"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import os
import dtale
import dtale.app as dtale_app

"""**Reading the dataset**"""

df=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Major Project/Dataset(1).csv",encoding='latin1')
a=pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Major Project/Dataset(1).csv",encoding='latin1')

"""**Data Pre-Processing and EDA**"""

a.dropna(subset=['Specific Yield Strength (MPa-cm3/g)'],inplace=True)

df.head(5)

df.describe()

df.isnull().sum()

df.dropna(subset=['Specific Yield Strength (MPa-cm3/g)'],inplace=True)

df['Composition(mole fraction)'].value_counts()

df['Testing T (Â°C)'].value_counts()

"""**Encoding**"""

le=LabelEncoder()
df['Composition(mole fraction)']=le.fit_transform(df['Composition(mole fraction)'])

final_data=pd.get_dummies(df,columns=['Single/ Multiphase material','Tension/ Compression'])
final_data.drop(columns=['Single/ Multiphase material_S','Tension/ Compression_C'],inplace=True)
y=final_data['Yield Strength (MPa)']
X=final_data.drop(columns=['Yield Strength (MPa)'])
X=final_data

dtale_app.USE_COLAB = True
dtale.show(final_data)

#sns.pairplot(data=final_data,aspect=2)

#sns.heatmap(data=final_data,annot=True,cmap='Reds')

"""**Splitting the data**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

"""**Linear Regressor**"""

lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
#Prediction using test set 
y_pred = lin_reg.predict(X_test)
mae=metrics.mean_absolute_error(y_test, y_pred)
mse=metrics.mean_squared_error(y_test, y_pred)
# Printing the metrics
print('R2 square:',metrics.r2_score(y_test, y_pred))
print('MAE: ', mae)
print('MSE: ', mse)

lin_reg.fit(X,y)
#path='/content/drive/MyDrive/Colab Notebooks/hema_major'
y_prediction=lin_reg.predict(X)
a['Y_prediction']=y_prediction
a.to_csv('/content/drive/MyDrive/Colab Notebooks/Major Project/output_lr.csv')

plt.figure(figsize=(7,7))
plt.scatter(y_test, y_pred, c='crimson')
#plt.yscale('log')
#plt.xscale('log')

p1 = max(max(y_pred), max(y_test))
p2 = min(min(y_pred), min(y_test))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()

"""**Decision Tree Regressor**"""

dt_regressor = DecisionTreeRegressor(random_state = 0)
dt_regressor.fit(X_train,y_train)
#Predicting using test set 
y_pred = dt_regressor.predict(X_test)
mae=metrics.mean_absolute_error(y_test, y_pred)
mse=metrics.mean_squared_error(y_test, y_pred)
# Printing the metrics
print('R2 square:',metrics.r2_score(y_test, y_pred))
print('MAE: ', mae)
print('MSE: ', mse)

dt_regressor.fit(X,y)
y_prediction=lin_reg.predict(X)
a['Y_prediction']=y_prediction
a.to_csv('/content/drive/MyDrive/Colab Notebooks/Major Project/output_Dr.csv')

plt.figure(figsize=(7,7))
plt.scatter(y_test, y_pred, c='crimson')
#plt.yscale('log')
#plt.xscale('log')

p1 = max(max(y_pred), max(y_test))
p2 = min(min(y_pred), min(y_test))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()

"""**Random Forest Regressor**"""

rf_regressor = RandomForestRegressor(n_estimators = 300 ,  random_state = 0)
rf_regressor.fit(X_train,y_train)
#Predicting the SalePrices using test set 
y_pred = rf_regressor.predict(X_test)
mae=metrics.mean_absolute_error(y_test, y_pred)
mse=metrics.mean_squared_error(y_test, y_pred)
# Printing the metrics
print('R2 square:',metrics.r2_score(y_test, y_pred))
print('MAE: ', mae)
print('MSE: ', mse)

rf_regressor.fit(X,y)
y_prediction=lin_reg.predict(X)
a['Y_prediction']=y_prediction
a.to_csv('/content/drive/MyDrive/Colab Notebooks/Major Project/output_Rr.csv')

plt.figure(figsize=(7,7))
plt.scatter(y_test, y_pred, c='crimson')
#plt.yscale('log')
#plt.xscale('log')

p1 = max(max(y_pred), max(y_test))
p2 = min(min(y_pred), min(y_test))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()

"""**Support Vectro Regressor**

"""

regressor= SVR(kernel='rbf')
regressor.fit(X_train,y_train)
y_pred_svm=regressor.predict(X_test)
mae=metrics.mean_absolute_error(y_test, y_pred_svm)
mse=metrics.mean_squared_error(y_test, y_pred_svm)
# Printing the metrics
print('R2 square:',metrics.r2_score(y_test, y_pred_svm))
print('MAE: ', mae)
print('MSE: ', mse)

regressor.fit(X,y)
y_prediction=lin_reg.predict(X)
a['Y_prediction']=y_prediction
a.to_csv('/content/drive/MyDrive/Colab Notebooks/Major Project/output_Sr.csv')

plt.figure(figsize=(7,7))
plt.scatter(y_test, y_pred, c='crimson')
#plt.yscale('log')
#plt.xscale('log')

p1 = max(max(y_pred), max(y_test))
p2 = min(min(y_pred), min(y_test))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('True Values', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()

##Pick the one with highest R2 score and least MAE